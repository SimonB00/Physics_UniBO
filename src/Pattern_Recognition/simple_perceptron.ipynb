{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebd242c5",
   "metadata": {},
   "source": [
    "# Python lecture - 24/03/2023\n",
    "\n",
    "In this lecture we'll overview the main characteristic of neural network and we'll see one of the easier ot them"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e0a1ebe",
   "metadata": {},
   "source": [
    "## Machine learning and deep learning\n",
    "\n",
    "This is a pattern recognition course, but it uses machine learning and deep learning to recognize images.\n",
    "So we can study machine learning and then apply this knowledge to pattern recognition.\n",
    "\n",
    "Machine learning and deep learning are not so different.\n",
    "We can approximate their relation in this way:\n",
    "\n",
    "$\\text{deep learning} \\subset \\text{machine learning} \\subset \\text{artificial intelligence}$\n",
    "\n",
    "To understand how a machine learns, we must know how our brain learns.\n",
    "We can divide this procedure in steps:\n",
    "1) **example:** someone (a teacher) or something (a book) teach us something and gives us example;\n",
    "2) **try:** we do some exercise similar to the examples;\n",
    "3) **errors:** we make mistakes in our exercise;\n",
    "4) **valuation:** how near our answers were similar to the correct answers;\n",
    "5) **comprention:** at the end we are able to resolve mostly correct all exercises.\n",
    "\n",
    "We can reproduce the same steps for a machine, but it will do them differently:\n",
    "1) **multiple data:** it takes a lot of data as starting information;\n",
    "2) **iterative process**: throw a for or while loop it iterate an algorithm that take as input the data and try to give as output the correct answer;\n",
    "3) **error function:** use a mathematical function to calculate how far is its answer to the correct answer. At the next iteration modify the algorithm to do better;\n",
    "4) **generalize:** at the end the machine will be able to give the correct answer almost always having as input a general data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98d00b24",
   "metadata": {},
   "source": [
    "## Neural network models\n",
    "\n",
    "It is one category of machine learning possibility.  \n",
    "It has two different approach:\n",
    "- *start from biological model and mathematize it*: they are inspired by how brain works but are not equal (Rosenblatt's perceptron, Hopfield's network, BCM theory, ...);\n",
    "- *physics / mathematical models*: they use physics models to let the machine learn (Boltzmann machine, convolutional NN, belief propagation, ...)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4baeea12",
   "metadata": {},
   "source": [
    "### Single perceptron\n",
    "\n",
    "The single perceptron is one of the easiest machine learning algorithms, and it is based on the neuron's mode of operation.\n",
    "\n",
    "#### Neurons\n",
    "\n",
    "A neuron has some dendrites that collect information (from other neurons or cells of different types) that arrive as action potential.\n",
    "The information are elaborated in the center of the cell that returns an output.\n",
    "If this output satisfies a particular condition -we can say this condition as a threshold- the neuron fires: an action potential is sent through the axon to other cells.\n",
    "\n",
    "How does the neuron elaborate the input?\n",
    "It analyzes the input and which cell sends it: if the input cell is usually synchronized with the neuron, their synapse is reinforced, otherwise the synapse's efficiency is reduced.\n",
    "This phenomenon is called ***synaptic plasticity*** because learning we modify our brain.\n",
    "The law that for the first time tries to describe the synaptic plasticity was the ***Hebbian theory***:  \n",
    "*let us assume that the persistence or repetition of a reverberatory activity (or \"trace\") tends to induce lasting cellular changes that add to its stability. ... When an axon of cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that Aâ€™s efficiency, as one of the cells firing B, is increased.*\n",
    "\n",
    "#### Now on the machine\n",
    "\n",
    "We can see the simpler perceptron as a box that:  \n",
    "*given some inputs it elaborates them with an algorithm to obtain an outcome that -after a threshold- returns if the input data is true or false respect a boolean question.*\n",
    "We can model the neuron's algorithm as a linear combination of the inputs:\n",
    "\n",
    "$y=f\\left(x\\right)= w_0 + w_1x_1 + w_2x_2 + \\dots + w_nx_n$\n",
    "\n",
    "where $x_i$ is the input'value of the $i$-th input, $w_i$ the weight of that input and $w_0$ the offset value.\n",
    "We can use as threshold a step function or -better- a sigmoid function.\n",
    "The synaptic plasticity is obtained modifying the weight: if when the input $i$ is True/False the correct answer is True/False, $w_i$ will increase (as the synaptic's efficiency in Hebb's model); otherwise $w_i$ will decrease."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd1cd1b4",
   "metadata": {},
   "source": [
    "## Coding\n",
    "\n",
    "Now we are trying to implement a simple perceptron to reproduce the logic function AND.\n",
    "\n",
    "First we must define variable:\n",
    "- $N\\_INPUT$: number of input that the function AND compares (so usually 2);\n",
    "- $weights$: an array that associates to each input a float number between 0 and 1 and represents the efficiency of the synapses;\n",
    "- $X$: an array that is our training set, so the combination of the input. In this case exist only four possible input;\n",
    "- $y$: an array that contain the correct outcome of any X input;\n",
    "- $GAMMA$: is how much the system learn in each epoch, so how much each exercise can modify the weight of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b137da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# the number of dendride == number of inputs\n",
    "N_INPUT = 2\n",
    "\n",
    "# the weight of the input: float between 0 and 1 of 2 numbers\n",
    "weights = np.random.uniform(low=0.0, high=1.0, size=N_INPUT)\n",
    "\n",
    "# all possible combinations of input\n",
    "X = np.array([[0, 1], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "# expected output of AND of X\n",
    "y = np.array([0, 0, 0, 1])\n",
    "\n",
    "# learning factor\n",
    "GAMMA = 1e-2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf997966",
   "metadata": {},
   "source": [
    "We introduce the $\\gamma$ to quantify how much the new iteration can modify the weight:\n",
    "\n",
    "$w_i\\left( \\theta + 1\\right) = w_i\\left(\\theta\\right) + \\gamma\\left( t - y\\right) x$\n",
    "\n",
    "so the weights at time $\\theta + 1$ depends on the weights at $\\theta$ and on the correctness of the result weighted with $\\gamma$.\n",
    "\n",
    "Now we have to create the iteration.\n",
    "At each epoch (iteration) we have to:\n",
    "1) scroll both arrays together;\n",
    "2) calculate the linear combination of inputs for each element of X;\n",
    "3) valuate the output respect the value of y;\n",
    "4) modify the weight to optimize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d3d34a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve(X, y, weights):\n",
    "    num_errors = 0\n",
    "    for xi, yi in zip(X, y):\n",
    "        output = np.sum(weights * xi) > 0  # predicted/obtained output\n",
    "        error = yi - output  # 0 or +/-1\n",
    "        # we have not to use an \"if\" statement because if error == 0 we sum 0\n",
    "        weights += (GAMMA * error) * xi\n",
    "        num_errors += abs(error)\n",
    "    return num_errors\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d424f47",
   "metadata": {},
   "source": [
    "Now we have to define what an epoch does.\n",
    "We create a \"while\" condition that it will stop if:\n",
    "- evolve does not return any error;\n",
    "- the loop has been iterated too many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "329caa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00947417 0.00728962]\n"
     ]
    }
   ],
   "source": [
    "MAX_ITER = 1000\n",
    "\n",
    "for epoch in range(MAX_ITER):\n",
    "    num_errors = evolve(X, y, weights)\n",
    "    if num_errors == 0:\n",
    "        break\n",
    "\n",
    "print(weights)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
