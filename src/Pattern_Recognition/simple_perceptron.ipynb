{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebd242c5",
   "metadata": {},
   "source": [
    "Python lecture - 24/03/2023\n",
    "\n",
    "In this lecture we'll overview the main characteristic of neural network and we'll see one of the easier ot them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0a1ebe",
   "metadata": {},
   "source": [
    "# Machine learning and deep learning\n",
    "\n",
    "This is a pattern recognition course, but it uses machine learninig and deep learninig to recognise images.\n",
    "So we can study machine learning and then apply these knowleg to pattern recognition.\n",
    "\n",
    "Machine learning and deep learning are not so different.\n",
    "We can approximize teir relation in this way:\n",
    "\n",
    "$\\text{deep learning} \\subset \\text{machine learning} \\subset \\text{artificial intelligence}$\n",
    "\n",
    "To understand how a machine learns, we must know how our brain learns.\n",
    "We can divide this procedure in steps:\n",
    "1) **example:** someone (a teacher) or something (a book) teach us sometihing and gives us example;\n",
    "2) **try:** we do some exercise similar to the examples;\n",
    "3) **errors:** we make mistakes in our exercise;\n",
    "4) **valuetion:** how near our answers were similar to the correct answers;\n",
    "5) **comprention:** at the end we are able to resolve mostly correcty all exercises.\n",
    "\n",
    "We can reproduce the same steps for a machine, but it will do them in a different way:\n",
    "1) **multiple data:** it takes a lot of data as starting information;\n",
    "2) **iterative process**: throw a for or while loop it iterate an algorithm that take as input the data and try to give as output the correct answer;\n",
    "3) **error function:** use a mathematical function to calculate how far is its answer to the correct answer. At the next iteration modify the algorithm to do better;\n",
    "4) **generalize:** at the end the machine will be able to give the correct answer almost always having as input a general data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d00b24",
   "metadata": {},
   "source": [
    "# Neural network models\n",
    "\n",
    "It is one cathegory of machine learning possibility.  \n",
    "It has two different approach:\n",
    "- *start from biological model and mathematize it*: they are ispired by how brain works but are not equal (Rosenblatt's perceptron, Hopfield's network, BCM theory, ...);\n",
    "- *physics / mathematical models*: they use physics models to let the machine to learn (Boltzmann machine, convolutional NN, belief proagation, ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baeea12",
   "metadata": {},
   "source": [
    "## Single perceptron\n",
    "\n",
    "The single perceptron is one of the easiest machine learning algorithms and it is based on the neuron's mode of operation.\n",
    "\n",
    "### Neurons\n",
    "\n",
    "A neuron has some dendrides that collect information (from other neurons or cells of different types) that arrive as action potential.\n",
    "The information are elaborated in the center of the cell that returns an output.\n",
    "If this output suddisfies a particular condition -we can say this condition as a threshold- the neuron fires: an action potential is send on the axon and it will arrive to other cells.\n",
    "\n",
    "How does the neuron elaborate the input?\n",
    "It analyze the input and which cell sends it: if the input cell is usually syncronize with the neuron, their synaps is renforced, otherwise the synaps's efficiency is reduced.\n",
    "This fenomena is called ***synaptic plasticity*** becouse learning we modify our brain.\n",
    "The law that for the first time tries to describe the synaptic plasticity was the ***Hebbian theory***:  \n",
    "*let us assume that the persistence or repetition of a reverberatory activity (or \"trace\") tends to induce lasting cellular changes that add to its stability. ... When an axon of cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that Aâ€™s efficiency, as one of the cells firing B, is increased.*\n",
    "\n",
    "### Now on the machine\n",
    "\n",
    "We can see the simpler perceptron as a box that:  \n",
    "*given some inputs it elaboreats them with an algorithm to obtain an outcome that -after a threshold- returns if the input data is true or false respect a boolean question.*\n",
    "We can modelize the neuron's algorithm as a linear combination of the inputs:\n",
    "\n",
    "$y=f\\left(x\\right)= w_0 + w_1x_1 + w_2x_2 + \\dots + w_nx_n$\n",
    "\n",
    "where $x_i$ is the input'value of the $i$-th input, $w_i$ the weight of that input and $w_0$ the offset value.\n",
    "We can use as threshold a step function or -better- a sigmoid function.\n",
    "The synaptic plasticity is obtained modifing the weight: if when the the input $i$ is True/False the correct asnwer is True/False, $w_i$ will increase (as the synaptic's efficiency in Hebb model); otherwise $w_i$ will decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1cd1b4",
   "metadata": {},
   "source": [
    "# Coding\n",
    "\n",
    "Now we are tring to implement a simple perceptron to reproduce the logic function AND.\n",
    "\n",
    "First of all we must to define variable:\n",
    "- N_INPUT: number of input that the function AND compares (so usually 2);\n",
    "- weights: an array that associats to each input a float number between 0 and 1 and rappresent the efficiency of the synaps;\n",
    "- X: an array that is our training set, so the combination of the input. In this case exist only four possible input;\n",
    "- y: an array that contain the correct outcome of any X input;\n",
    "- GAMMA: is how much the system learn in each epoch, so how much each exercise can modifies the weight of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b137da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#the number of dendride == number of inputs\n",
    "N_INPUT = 2\n",
    "\n",
    "#the weight of the input: float between 0 and 1 of 2 numbers\n",
    "weights = np.random.uniform(low=0., high=1., size=N_INPUT)\n",
    "\n",
    "#all possible combinations of input\n",
    "X = np.array([[0,1], [0,1], [1,0], [1,1]])\n",
    "\n",
    "#expected output of AND of X\n",
    "y = np.array([0, 0, 0, 1])\n",
    "\n",
    "#learning factor\n",
    "GAMMA = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf997966",
   "metadata": {},
   "source": [
    "We introduce the $\\gamma$ to quantify how much the new iteration can modify the weight:\n",
    "\n",
    "$w_i\\left( \\theta + 1\\right) = w_i\\left(\\theta\\right) + \\gamma\\left( t - y\\right) x$\n",
    "\n",
    "so the weights at time $\\theta + 1$ depends on the weights at $\\theta$ and on the correctness of the result weighted with $\\gamma$.\n",
    "\n",
    "Now we have to create the iteration.\n",
    "At each epoch (iteration) we have to:\n",
    "1) scroll both arrays togheder;\n",
    "2) calculate the linear combination of inputs for each element of X;\n",
    "3) valuate the output respect the value of y;\n",
    "4) modify the weight to optimize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d3d34a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve(X, y, weights):\n",
    "    num_errors = 0\n",
    "    for xi, yi in zip(X, y):\n",
    "        output = np.sum(weights * xi) > 0 #predicted/ obtained output\n",
    "        error = yi - output #0 or +/-1\n",
    "         #we have not to use an \"if\" becouse if error == 0 we sum 0\n",
    "        weights += (GAMMA * error) * xi\n",
    "        num_errors += abs(error)\n",
    "    return num_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d424f47",
   "metadata": {},
   "source": [
    "Now we have to define what an epoch does.\n",
    "We create a \"while\" condition that it will stop if:\n",
    "- evolve does not return any error;\n",
    "- the loop was been iterate too many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "329caa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00947417 0.00728962]\n"
     ]
    }
   ],
   "source": [
    "iter1 = 0\n",
    "MAX_ITER = 1000\n",
    "\n",
    "while iter1 < MAX_ITER:\n",
    "    iter1 += 1\n",
    "    num_errors = evolve(X, y, weights)\n",
    "    if num_errors == 0:\n",
    "        break\n",
    "        \n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5996624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
